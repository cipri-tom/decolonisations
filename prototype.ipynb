{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path, listdir\n",
    "\n",
    "from lxml import etree\n",
    "from lxml.etree import XPath\n",
    "import pickle as pkl\n",
    "from itertools import filterfalse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hack to avoid passing the namespace all the time; from http://stackoverflow.com/a/17293795/786559\n",
    "# etree.FunctionNamespace(\"http://exslt.org/regular-expressions\").prefix = 're'\n",
    "re_NS = {'re': \"http://exslt.org/regular-expressions\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_file(journal_path, min_year=None, max_year=None):\n",
    "    \"\"\" Returns a the filename to process next, along with its year and month. \n",
    "        If the range is given, then only those years are considered \"\"\"\n",
    "    for year in listdir(journal_path):\n",
    "        # filter range:\n",
    "        if min_year and int(year) < min_year or \\\n",
    "           max_year and int(year) > max_year:\n",
    "            continue\n",
    "            \n",
    "        year_path = path.join(journal_path, year)\n",
    "        for filename in listdir(year_path):\n",
    "            month = path.splitext(filename)[0]\n",
    "            yield path.join(year_path, filename), int(year), int(month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_xpath_search(word_list):\n",
    "    \"\"\" Given the word list, returns an XPath search function returning articles whose full_text matches any of those\n",
    "    words\"\"\"\n",
    "    match_string = './/full_text[re:test(text(), \"{regex}\", \"i\")]//ancestor::article'.format(regex='|'.join(word_list))\n",
    "    return XPath(match_string, namespaces=re_NS)\n",
    "    # no need to pass the namespaces, because of the 'hack' above\n",
    "#     return etree.XPath(match_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_path = '/home/tomoiaga/hum_dig/results/'\n",
    "\n",
    "# set the searches\n",
    "search_text = XPath('.//full_text/text()')\n",
    "search_date = XPath('./entity/issue_date/text()')\n",
    "\n",
    "def export_iramu(articles, country_name):\n",
    "    \"\"\" Appends all the articles to the country's file \"\"\"\n",
    "    file_name = path.join(result_path, country_name + '.txt')\n",
    "    # pays, date_an, date_mois, date_jour, journal, len_mots, len_chars\n",
    "    article_template = \"**** *p_{country} *da_{year} *dm_{month} *dj_{day} j_{journal} *lm_{words} *lc_{chars}\"\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    with open(file_name, 'a') as f:\n",
    "        for art in articles:\n",
    "            \n",
    "            \n",
    "            \n",
    "            texts = to_text(art)\n",
    "            f.write(' '.join(texts).replace('*', ' '))\n",
    "            f.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_articles(countries, with_words, without_words, min_year=None, max_year=None):\n",
    "    \"\"\" countries = [                                   # list of countries\n",
    "            {                                           # each country is a dict\n",
    "                'name'     : 'Burundi'                  # the current name\n",
    "                'alt_names': ['Urundi', 'Urundi-Ghana'],# other names that it was known as \n",
    "                \n",
    "                # the function adds these:\n",
    "                'path'     : XPath(names),              # an XLST search path for 'alt_names'\n",
    "                'articles' : []                         # the list of articles corresponding to this country\n",
    "            }\n",
    "        ] \"\"\"\n",
    "\n",
    "    # prepare the structure\n",
    "    for country in countries:\n",
    "        country['path'] = get_xpath_search(country['alt_names'])\n",
    "        country['articles'] = []\n",
    "\n",
    "    # prepare the AND and EXCLUDE filters\n",
    "    and_filter = get_xpath_search(with_words)\n",
    "    if without_words:\n",
    "        not_filter = get_xpath_search(without_words)\n",
    "    else:\n",
    "        not_filter = None\n",
    "\n",
    "    root_path = \"/mnt/le_temps_data/letempsdata/data4-month/\"\n",
    "    for journal in ['GDL', 'JDG']:\n",
    "        journal_path = path.join(root_path, journal)\n",
    "        for file_path, year, month in get_next_file(journal_path, min_year, max_year):\n",
    "            with open(file_path) as f:\n",
    "                tree = etree.parse(f)\n",
    "                \n",
    "                for country in countries:\n",
    "                    all_articles = country['path'](tree)\n",
    "                    filtered = filter(and_filter, all_articles)\n",
    "                    if not_filter is not None:\n",
    "                        filtered = filter(not_filter, filtered)\n",
    "                    \n",
    "                    # save into the data structure\n",
    "                    country['articles'].extend(filtered)\n",
    "        \n",
    "    return countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = etree.parse('./text.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = get_xpath_search(['12', '2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "As = s(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = As[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element article at 0x7f566c10dc08>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t.xpath('.//full_text[re:test(text(), \"text\") and re:test(text(), \"7\") and not(re:test(text(), \"1\"))]/ancestor::article', namespaces=re_NS)\n",
    "t.xpath('.//full_text[re:test(text(), \"text\") and re:test(text(), \"[0-9]{2}\")  and not(re:test(text(), \"2\"))]/ancestor::article', namespaces=re_NS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01/02/1798']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.xpath('./entity[1]/meta/issue_date[1]/text()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = etree.XPath('.//full_text[re:test(text(),\"12\")]//ancestor::article', namespaces=re_NS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element article at 0x7fefaf939608>]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(f, filter(f, As)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, [4], {5}, '6']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: x, [2, 3, [4], {5}, '6', None, [], {}, \"\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yee\n"
     ]
    }
   ],
   "source": [
    "if [2]:\n",
    "    print(\"Yee\")\n",
    "else:\n",
    "    print(\"noo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//full_text[re:match(text(), \"Angola\")]//ancestor::article\n"
     ]
    }
   ],
   "source": [
    "arts = get_articles(['Angola'], 1965, 1980)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "export_iramu(arts, 'angola.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2460"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = arts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter(withtout(words), articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def without(word):\n",
    "    has_word = etree.XPath('.//full_text[contains(text(), \"{w}\")]'.format(w=word))\n",
    "    def predicate(article):\n",
    "        return len(has_word(article)) == 0\n",
    "    return predicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def with_filter(word):\n",
    "    has_word = etree.XPath('.//full_text[contains(text(), \"{w}\")]'.format(w=word))\n",
    "    def predicate(article):\n",
    "        return len(has_word(article)) > 0\n",
    "    return predicate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Angola AND Deco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(filter(with_filter('décolonisation'), arts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//full_text[re:match(text(), \"décolonisation\")]//ancestor::article\n"
     ]
    }
   ],
   "source": [
    "tous_deco = get_articles(['décolonisation'], 1945, 1990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export_iramu(tous_deco, 'decolonisation.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tous_deco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//full_text[re:match(text(), \"burundi\", \"i\")]//ancestor::article\n"
     ]
    }
   ],
   "source": [
    "burundi = get_articles(['burundi'], 1952, 1967)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(burundi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export_iramu(burundi, 'burundi.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "burundi_congo = list(filter(with_filter('congo'), burundi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265\n"
     ]
    }
   ],
   "source": [
    "algerie = get_articles(['algerie'], 1952, 1967)\n",
    "print(len(algerie))\n",
    "export_iramu(algerie, 'algerie.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "find_articles = etree.XPath('//full_text[starts-with(text(), \"que\")]//ancestor::article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "find_articles = etree.XPath('//full_text[re:match(text(), \"^que\")]//ancestor::article', namespaces={\"re\": \"http://exslt.org/regular-expressions\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element article at 0x7fefafc81ec8>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "find_articles = get_xpath_search(['points', 'armeé'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t.findall('article'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
